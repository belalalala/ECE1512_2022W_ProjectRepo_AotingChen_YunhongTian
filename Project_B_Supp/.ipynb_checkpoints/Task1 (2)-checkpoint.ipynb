{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WYMfvCNPwpm"
   },
   "source": [
    "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vA8ppgB2P0aJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:22:41.248120: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Union\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "builder = tfds.builder('mnist')\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 12\n",
    "NUM_CLASSES = 10  # 10 total classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "9cxw0PzE53Zk"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras_flops import get_flops\n",
    "import keras.backend as K\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2EFLQROP2R7"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "403be929e9024411a153c32a8d9e7faa",
      "40bc4ccbe60443ce98c9d1abd0dcfea7",
      "a943481bd0e543e98336d234af4dd764",
      "7ebc9447af7a4dd4aaadb32491bb47eb",
      "3fc0ac74e6574800a761e017f6a096a6",
      "90b50d41596f42e2b5d347f349746c67",
      "b793841591f84ba2a70a8d592216e5bd",
      "9855b4675bcc4a0b93606d95022ebca2",
      "25012ac4cf7441f693687fa97e861e7f",
      "ade6bef4ba3b42f2af4cf92b536cae6b",
      "38022535a8ae4875ad8cb2ae43189284"
     ]
    },
    "id": "ynByMG_UP4A4",
    "outputId": "ae0810ce-be66-46bb-f6a4-3fbb49f64caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/nealcaffrey/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3001922960ef45f69de2179f6a67e5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/nealcaffrey/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:22:49.096397: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load train and test splits.\n",
    "def preprocess(x):\n",
    "  image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
    "  subclass_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
    "  return image, subclass_labels\n",
    "\n",
    "\n",
    "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
    "mnist_train = mnist_train.map(preprocess)\n",
    "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
    "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "mnist_test = tfds.load('mnist', split='test').cache()\n",
    "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAZwfvW5P63q"
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7xptSiA9hat",
    "outputId": "8e0fd5a4-5fda-4de6-c3b1-afc5eb773fc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zINgDkA7P7BP",
    "outputId": "4bfe9c13-488c-43c0-fe17-15edf8b23660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher model summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "student model summary\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,238,730\n",
      "Trainable params: 1,238,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##@test {\"output\": \"ignore\"} \n",
    "\n",
    "# Build CNN teacher.\n",
    "# cnn_model\n",
    "teacher_model = tf.keras.Sequential()\n",
    "\n",
    "# your code start from here for stpe 2\n",
    "teacher_model.add(Conv2D(32, (3, 3), strides = (1, 1), activation='relu', input_shape=(28,28,1)))\n",
    "teacher_model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
    "teacher_model.add(Conv2D(64, (3, 3), strides = (1, 1), activation='relu'))\n",
    "teacher_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "teacher_model.add(Flatten())\n",
    "teacher_model.add(Dropout(0.5))\n",
    "teacher_model.add(Dense(128, activation='relu'))\n",
    "teacher_model.add(Dropout(0.5))\n",
    "teacher_model.add(Dense(10))\n",
    "\n",
    "\n",
    "print('teacher model summary')\n",
    "print(teacher_model.summary())\n",
    "\n",
    "\n",
    "# Build fully connected student.\n",
    "# fc_model\n",
    "student_model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "# your code start from here for step 2\n",
    "student_model.add(tf.keras.Input(shape=(28,28,1)))\n",
    "student_model.add(Flatten())\n",
    "student_model.add(Dense(784, activation='relu'))\n",
    "student_model.add(Dense(784, activation='relu'))\n",
    "student_model.add(Dense(10))\n",
    "\n",
    "print('student model summary')\n",
    "print(student_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JWGucyrQGav"
   },
   "source": [
    "# Teacher loss function\n",
    "Complete function compute teacher loss for loss (objective) function of the teacher model in the “Teacher loss function” section. Similarly, write your program in distillation loss and com- pute student loss functions to define the loss (objective) function of the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "DhzBP6ZLQJ57"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_teacher_loss(images, labels):\n",
    "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
    "     and labels.\n",
    "\n",
    "  Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Scalar loss Tensor.\n",
    "  \"\"\"\n",
    "  subclass_logits = teacher_model(images, training=True)\n",
    "\n",
    "  # Compute cross-entropy loss for subclasses.\n",
    "\n",
    "  # your code start from here for step 3\n",
    "  cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits)\n",
    "  # teacher_probs = tf.nn.softmax(subclass_logits)\n",
    "  # cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy( labels,teacher_probs)\n",
    "  return tf.reduce_mean(cross_entropy_loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS8xkuH0QbOS"
   },
   "source": [
    "# Student loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distillation loss and student loss Code refer to Reference[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDKia4gPQMIr"
   },
   "outputs": [],
   "source": [
    "##@test {\"output\": \"ignore\"}\n",
    "\n",
    "# Hyperparameters for distillation (need to be tuned).\n",
    "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
    "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
    "\n",
    "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
    "                      temperature: Union[float, tf.Tensor]):\n",
    "  \"\"\"Compute distillation loss.\n",
    "\n",
    "  This function computes cross entropy between softened logits and softened\n",
    "  targets. The resulting loss is scaled by the squared temperature so that\n",
    "  the gradient magnitude remains approximately constant as the temperature is\n",
    "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
    "  a neural network.\"\n",
    "\n",
    "  Args:\n",
    "    teacher_logits: A Tensor of logits provided by the teacher.\n",
    "    student_logits: A Tensor of logits provided by the student, of the same\n",
    "      shape as `teacher_logits`.\n",
    "    temperature: Temperature to use for distillation.\n",
    "\n",
    "  Returns:\n",
    "    A scalar Tensor containing the distillation loss.\n",
    "  \"\"\"\n",
    " # your code start from here for step 3\n",
    "  soft_targets = tf.nn.softmax(teacher_logits/temperature)\n",
    "\n",
    "  return tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
    "\n",
    "def compute_student_loss(images, labels):\n",
    "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
    "     and labels.\n",
    "\n",
    "  Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Scalar loss Tensor.\n",
    "  \"\"\"\n",
    "  student_subclass_logits = student_model(images, training=True)\n",
    "\n",
    "  # Compute subclass distillation loss between student subclass logits and\n",
    "  # softened teacher subclass targets probabilities.\n",
    "\n",
    "  # your code start from here for step 3\n",
    "\n",
    "  teacher_subclass_logits = teacher_model(images, training=False)\n",
    "  distillation_loss_value = distillation_loss(teacher_subclass_logits,student_subclass_logits,DISTILLATION_TEMPERATURE)\n",
    "\n",
    "  # Compute cross-entropy loss with hard targets.\n",
    "\n",
    "  # your code start from here for step 3\n",
    "\n",
    "  cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_subclass_logits))\n",
    "\n",
    "  BETA = 1-ALPHA\n",
    "  total_loss = (ALPHA * cross_entropy_loss_value) + (BETA * distillation_loss_value)\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ1uyvurQ3w4"
   },
   "source": [
    "# Train and evaluation\n",
    "To perform training and evaluation for a given model, complete the function train and evaluate in the section “Train and evaluation”. The optimizer should be Adam, with a learning rate of 0.001 for all models. (Hint: The function compute num correct has already been implemented for you to compute the number of correctly classified images in a batch. Use this function to evaluate your model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Code refer to Reference[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtoLbp8uQ4Vl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_num_correct(model, images, labels):\n",
    "  \"\"\"Compute number of correctly classified images in a batch.\n",
    "\n",
    "  Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Number of correctly classified images.\n",
    "  \"\"\"\n",
    "  class_logits = model(images, training=False)\n",
    "  return tf.reduce_sum(\n",
    "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
    "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, compute_loss_fn):\n",
    "  \"\"\"Perform training and evaluation for a given model.\n",
    "\n",
    "  Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    compute_loss_fn: A function that computes the training loss given the\n",
    "      images, and labels.\n",
    "  \"\"\"\n",
    "\n",
    "  # your code start from here for step 4\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "  for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    # Run training.\n",
    "    print('Epoch {}: '.format(epoch), end='')\n",
    "    for images, labels in mnist_train:\n",
    "      with tf.GradientTape() as tape:\n",
    "         # your code start from here for step 4\n",
    "#         loss_value = tf.reduce_mean(compute_loss_fn(labels,model(images, training=True),from_logits=True))\n",
    "        loss_value = compute_loss_fn(images,labels)\n",
    "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Run evaluation.\n",
    "    num_correct = 0\n",
    "    num_total = builder.info.splits['test'].num_examples\n",
    "    for images, labels in mnist_test:\n",
    "      # your code start from here for step 4\n",
    "      temp = compute_num_correct(model, images, labels)\n",
    "      # print(temp)\n",
    "      num_correct += temp[0]\n",
    "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
    "        num_correct / num_total * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQL1lJdaRPT1"
   },
   "source": [
    "# Training models\n",
    "Train the teacher (the student, resp.) model for 12 epochs with compute teacher loss (com- pute student loss, resp.) in the pre-assigned “Training models” section of Task1.ipynb file. Upon completion of training, evaluate the performance of the trained teacher and the student model on the test data, assuming that the most-confident class is predicted for each image. Report the test accuracy for both the teacher and student models. (Note that in this part, you need to tune the distillation hyperparameters, such as task balance α and the distillation temperature, T.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-AGHbyABRPz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 99.20%\n",
      "Epoch 2: Class_accuracy: 99.16%\n",
      "Epoch 3: Class_accuracy: 99.20%\n",
      "Epoch 4: Class_accuracy: 99.28%\n",
      "Epoch 5: Class_accuracy: 99.24%\n",
      "Epoch 6: Class_accuracy: 99.29%\n",
      "Epoch 7: Class_accuracy: 99.28%\n",
      "Epoch 8: Class_accuracy: 99.25%\n",
      "Epoch 9: Class_accuracy: 99.32%\n",
      "Epoch 10: Class_accuracy: 99.31%\n",
      "Epoch 11: Class_accuracy: 99.28%\n",
      "Epoch 12: Class_accuracy: 99.29%\n"
     ]
    }
   ],
   "source": [
    "# your code start from here for step 5 \n",
    "# teacher\n",
    "# for images, labels in mnist_train:\n",
    "#     loss = compute_teacher_loss(images,labels)\n",
    "#     train_and_evaluate(teacher_model,loss)\n",
    "# loss = compute_teacher_loss(image,label)\n",
    "# # # train_and_evaluate(teacher_model,tf.keras.losses.categorical_crossentropy)\n",
    "\n",
    "train_and_evaluate(teacher_model,compute_teacher_loss)\n",
    "\n",
    "# train_and_evaluate(teacher_model,tf.keras.losses.categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 8.92%\n",
      "Epoch 2: Class_accuracy: 8.92%\n",
      "Epoch 3: Class_accuracy: 8.92%\n",
      "Epoch 4: Class_accuracy: 8.92%\n",
      "Epoch 5: Class_accuracy: 9.23%\n",
      "Epoch 6: Class_accuracy: 8.92%\n",
      "Epoch 7: Class_accuracy: 9.74%\n",
      "Epoch 8: Class_accuracy: 8.92%\n",
      "Epoch 9: Class_accuracy: 8.92%\n",
      "Epoch 10: Class_accuracy: 9.74%\n",
      "Epoch 11: Class_accuracy: 9.74%\n",
      "Epoch 12: Class_accuracy: 8.92%\n"
     ]
    }
   ],
   "source": [
    "# tuned hyperparameters: task balance α = 4, distillation temperature T = 4, learning rate = 0.001\n",
    "train_and_evaluate(student_model,compute_student_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj1N38fnRTNB"
   },
   "source": [
    "# Test accuracy vs. tempreture curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"student\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,238,730\n",
      "Trainable params: 1,238,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load our trained model 1\n",
    "# if using jupyter notebook\n",
    "student_modelKD=load_model('/Users/nealcaffrey/Desktop/ece1512/Project_B_Supp/student_modelKD1.h5')\n",
    "# if using collab\n",
    "# student_modelKD=load_model('/content/student_modelKD1.h5')\n",
    "student_modelKD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code start from here for step 6\n",
    "def compute_student_loss2(images, labels):\n",
    "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
    "     and labels.\n",
    "\n",
    "  Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Scalar loss Tensor.\n",
    "  \"\"\"\n",
    "  student_subclass_logits = student_modelKD(images, training=True)\n",
    "\n",
    "  # Compute subclass distillation loss between student subclass logits and\n",
    "  # softened teacher subclass targets probabilities.\n",
    "\n",
    "  # your code start from here for step 3\n",
    "\n",
    "  teacher_subclass_logits = teacher_model(images, training=False)\n",
    "  distillation_loss_value = distillation_loss(teacher_subclass_logits,student_subclass_logits,DISTILLATION_TEMPERATURE)\n",
    "\n",
    "  # Compute cross-entropy loss with hard targets.\n",
    "\n",
    "  # your code start from here for step 3\n",
    "\n",
    "  cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_subclass_logits))\n",
    "\n",
    "  BETA = 0.5\n",
    "  total_loss = (ALPHA * cross_entropy_loss_value) + (BETA * distillation_loss_value)\n",
    "\n",
    "  return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "gX4dbazrRWIz"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 6\n",
    "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
    "DI_TEMPERATURE = [1,2,4,16,32,62]\n",
    "acc6 = [0,0,0,0,0,0]\n",
    " #temperature hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0974"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code start from here for step 6\n",
    "def train_and_evaluate2(model, compute_loss_fn):\n",
    "  \"\"\"Perform training and evaluation for a given model.\n",
    "\n",
    "  Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    compute_loss_fn: A function that computes the training loss given the\n",
    "      images, and labels.\n",
    "  \"\"\"\n",
    "\n",
    "  # your code start from here for step 4\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "  for epoch in range(3):\n",
    "    # Run training.\n",
    "    # print('Epoch {}: '.format(epoch), end='')\n",
    "    for images, labels in mnist_train:\n",
    "      with tf.GradientTape() as tape:\n",
    "         # your code start from here for step 4\n",
    "#         loss_value = tf.reduce_mean(compute_loss_fn(labels,model(images, training=True),from_logits=True))\n",
    "        loss_value = compute_loss_fn(images,labels)\n",
    "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Run evaluation.\n",
    "    num_correct = 0\n",
    "    num_total = builder.info.splits['test'].num_examples\n",
    "    for images, labels in mnist_test:\n",
    "      # your code start from here for step 4\n",
    "      temp = compute_num_correct(model, images, labels)\n",
    "      num_correct += np.sum(temp[0])\n",
    "    # print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
    "    #     num_correct / num_total * 100))\n",
    "    accF = num_correct / num_total\n",
    "  return accF\n",
    "\n",
    "train_and_evaluate2(student_modelKD,compute_student_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (6):\n",
    "  DISTILLATION_TEMPERATURE = DI_TEMPERATURE[i]\n",
    "  acc6[i] = train_and_evaluate2(student_modelKD,compute_student_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8adfa1100>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABBXUlEQVR4nO3deXhU9dXA8e/JTBaSsIUEZN93JGwibhQErVoVteIC7Vvtq32tYNVa61Ktttpq6664lFprq+C+W8SSCKJWKrsswyb7YhJ2AklmMvN7/7g3YYhJZiZkcmc5n+eZJzN37r1z7iSZM79djDEopZRS4UpxOgCllFLxRROHUkqpiGjiUEopFRFNHEoppSKiiUMppVRENHEopZSKiCYOpZRSEdHEkaBEpDToFhCRsqDHkxtwvnkick00YlUgIptFZLzTcYRDRMaIyHan41DOcTsdgIoOY0x21X0R2QxcY4wpcC6i6BIRtzGm0uk4EkG030unflciIoAYYwJN/dqJRkscSUZEUkTkdhH5RkT2iMjrIpJjP5chIi/b2/eLyEIRaScifwDOAKbZJZZpdZz7DRH5VkQOiMh8ERkY9FwzEXlERLbYz38uIs3s504Xkf/Yr7lNRK6ytx9TyhGRq0Tk86DHRkSmiMh6YL297Qn7HAdFZLGInBG0v0tE7rSv/ZD9fGcReVpEHqlxLR+IyE21XONzIvJwjW3vicgv7fu3icgO+/xrRWRcGL+Tl4AuwAf2+/tre/uooPdluYiMCTpmnojcbz9fasfbRkRm2Ne+UES61XivfiEiG0Vkt4g8JCIpQe/rFyLymIjsBe4VkXQReVhEtopIkX3dzUQkC/gI6BBUgu0gIi+KyP1Br3dMqcQuUd0mIl8Dh0XEXd/11fIedRaRt0WkxP77nGZvv1dEXg7ar5t9re6g9+kPIvIFcAS4U0QW1Tj3zSLyvn2/1usO9TtMOsYYvSX4DdgMjLfv3wQsADoB6cBfgFfs5/4P+ADIBFzAcKCF/dw8rFJLfa/zU6C5fd7HgWVBzz1tn6Ojfe5T7f26AIeAK4FUoA0wpLbXBK4CPg96bIA5QA7QzN72I/scbuAW4Fsgw37uVmAF0BcQIN/edySwE0ix98vF+pBpV8s1jga2YX1zBWgNlAEd7PNuAzrYz3UDekb6O7IfdwT2AOdhfcE7y36cF/TebAB6Ai2B1cA6YLx97f8E/l7jvZprv1dd7H2vCXpfK4Eb7GOb2b+/9+39m9t/Fw/Y+48BtteI/0Xg/qDHx+xjX98yoLN9/nqvr8a5XcBy4DEgC8gATrefuxd4OWjfbva1uoPep63AQPvaWmL9vfUOOmYhcIV9v87r1lvQ78TpAPTWBL/kYxOHBxgX9Fx7wGf/U/0U+A8wuJZzzCNE4qixfyv7H7il/cFQBuTXst8dwDt1nOOY16T2xHFmiDj2Vb0usBaYUMd+HuAs+/5UYFYd+4n9QTTafnwt8Il9vxdQjPXhndrQ35H9+DbgpRr7fAz8JOi9+U3Qc48AHwU9voBjE7cBzgl6fD1QGPS+bq1xjYcJSnrAKcAm+/4YGpY4fhru9dXYfgpQgp0Majx3L6ETx+9rHPMy8Fv7fm+sRJIZ6rr1dvSmVVXJpyvwjl09sB/rA9MPtANewvrnfVVEdorIn0UkNZyT2tVAD9rVQAexPijA+vaei/Ut8ZtaDu1cx/ZwbasRxy0i4hGrOmw/VuLKDeO1/oFVWsH++VJtOxnr0+RVrBISwCRghv3cBqwS3b1AsYi8KiIdIr8kwPo9Taz6PdnXcjpWoq9SFHS/rJbH2Rwr+L3aglVKqu25PKwP0sVBrz3b3n48gl8jnOur0hnYYhreLrKtxuOZHPv7e9cYc4ToXXfC0cSRfLYB5xpjWgXdMowxO4wxPmPM74wxA7Cqks4H/sc+LtQ0ypOACVjftltiffMD61vcbqAcq1qltnhq2w7Wt7/MoMcn1LJPdVx2e8ZtwGVAa2NMK+CAHUOo13oZmCAi+UB/4N069gN4BbhURLoCJwNvVQdjzExjzOlYH4wG+FM956n1OoJifanG7ynLGPNgmOerTeeg+12wqudqe/3dWIlnYNBrtzRHO1zU9rcQ0e+KyK5vG9Clqt3iOF8X4N9ArogMwUogM+3toa5b2TRxJJ/ngD/YH3qISJ6ITLDvjxWRE0XEBRzEqsLy28cVAT3qOW9zoAKrnjoT+GPVE8bqxfIC8KjdkOoSkVNEJB3r2/p4EbnMbjBtY/9Dg1UnfomIZIpIL+B/Q1xbc6y6+hLALSK/BVoEPf88cJ+I9BbLYBFpY8e4Hauu+yXgLWNMWV0vYoxZar/G88DHxpj9ACLSV0TOtK+rHOtDyF/XeWqo+f6+DFwgIt+3368Mu8G5U5jnq82tItJaRDoDNwKv1baT/fv6K/CYiLQFEJGOIvL9oFjbiEjLoMOWAeeJSI6InIBV8qpPJNf3FbALeFBEsux9Twt63dEi0sWO544Qr4tdcnkTeAirLWNOmNetbJo4ks8TWI1//xaRQ1gN5Sfbz52A9Q91EKsK61Osf/Cq4y4VkX0i8mQt5/0nVvXHDqyG2gU1nv8VVsP0QmAv1jfxFGPMVqwG0lvs7cuwGq3Bagz1Yn1Q/QO7SqgeH2P1+Flnx1LOsdUUjwKvY33jPAj8Dauhtso/gBOpo5qqhlewSlczg7alAw9ifXP9FmgL3AkgIpNFZFU953sAuMuuIvmVMWYbVgnuTqwktQ2rcf94/mffAxZjvcf/wrr+utyG1fi+wK56LMBq/McYswbr+jfa8XbAes+WY1VR/ps6klKVSK7PGOPHarPphdW+tB243H5ujv1aX9vX9mG978BRM7F+f2/UqAKr87rVUVU9Q5RKeiIyGitRdjMJ1tdfRAxWT6INTsei4p+WOJQC7E4ANwLPJ1rSUKqxaeJQSU9E+gP7sXr0PO5oMErFAa2qUkopFREtcSillIpIUkxymJuba7p16+Z0GEopFVcWL1682xjznQGQSZE4unXrxqJFi0LvqJRSqpqIbKltu1ZVKaWUiogmDqWUUhHRxKGUUioiSdHGoZRKbD6fj+3bt1NeXu50KHEpIyODTp06kZoa1mTYmjiUUvFv+/btNG/enG7duiEioQ9Q1Ywx7Nmzh+3bt9O9e/ewjtGqKqVU3CsvL6dNmzaaNBpARGjTpk1EpTVNHEqphKBJo+Eife+0qipCm3cfZtu+I5zRWxcFC7Zw814+W1fidBjxS4QL89vTq21zpyNRKiRNHBH662cb+XjVtyy66yynQ4kZxhhufWM5m/ccQb/0NYwx8NrCrfzrF2eQm53udDhK1SuqiUNEzsFaAMiFNV31d5aFFJExWDOSpgK7jTHfq+9YEbkXuBZr8ReAO40xs6J5HcHKfH4OljV06ePE9E3JYTbvOcJ9Fw3ix6O6Oh1OXFq98yAXP/MFN726jH/8dCSuFM3A6rsqKytxu53/vh+1Ng57+dGngXOBAcCVIjKgxj6tgGeAC40xA4GJYR77mDFmiH1rsqQB4PMbvP4A3kpdsqFKoacIgHH92jocSfwa0KEFv58wkM837GbaJ7rWUjy66KKLGD58OAMHDmT69OkAzJ49m2HDhpGfn8+4ceMAKC0t5eqrr+bEE09k8ODBvPWWtWR9dvbRpc3ffPNNrrrqKgCuuuoqfvnLXzJ27Fhuu+02vvrqK0499VSGDh3Kqaeeytq1awHw+/386le/qj7vU089RWFhIRdffHH1eefMmcMll1xy3NcazdQ1EthgjNkIICKvYi0VuTpon0nA2/byoRhjiiM41hHeSmsJ6cMVlaS50xyOJjYUeIoY2KEFHVo1C72zqtNlIzrz3017ebxwHSO6tea0XrlOhxSXfvfBKlbvPNio5xzQoQX3XDCw3n1eeOEFcnJyKCsr46STTmLChAlce+21zJ8/n+7du7N3714A7rvvPlq2bMmKFSsA2LdvX8jXX7duHQUFBbhcLg4ePMj8+fNxu90UFBRw55138tZbbzF9+nQ2bdrE0qVLcbvd7N27l9atWzNlyhRKSkrIy8vj73//O1dfffVxvx/R7FXVkWPXe95ubwvWB2gtIvNEZLGI/E+Yx04Vka9F5AURaV3bi4vIz0RkkYgsKilpvEZbn99av+SwV6urAPYe9rJ4yz7G9W/ndChxT0S4/6JB9MrL5sZXl1J0UAezxZMnn3yS/Px8Ro0axbZt25g+fTqjR4+uHhuRk5MDQEFBAVOmTKk+rnXrWj/CjjFx4kRcLhcABw4cYOLEiQwaNIibb76ZVatWVZ/3uuuuq67KysnJQUT48Y9/zMsvv8z+/fv58ssvOffcc4/7WqNZ4qitkrbmqlFuYDgwDmgGfCkiC0Ic+yxwn/34PuAR4Kff2dmY6cB0gBEjRjTaalVVVVSHK/yNdcq4NndNMQEDZ2niaBSZaW6emTyMC6d9wQ2vLGXmNSfjdmmv+UiEKhlEw7x58ygoKODLL78kMzOTMWPGkJ+fX12NFMwYU2v31+BtNcdUZGVlVd+/++67GTt2LO+88w6bN29mzJgx9Z736quv5oILLiAjI4OJEyc2ShtJNP8itwOdgx53AnbWss9sY8xhY8xuYD6QX9+xxpgiY4zfXhf6r1jVWk3G67cSR2mFljjAqqZq1yKdQR1bOB1Kwujdrjl/vGQQX23ay6Nz1jkdjgrDgQMHaN26NZmZmaxZs4YFCxZQUVHBp59+yqZNmwCqq6rOPvtspk2bVn1sVVVVu3bt8Hg8BAIB3nnnnXpfq2NHqwLmxRdfrN5+9tln89xzz1FZWXnM63Xo0IEOHTpw//33V7ebHK9oJo6FQG8R6S4iacAVwPs19nkPOENE3CKSCZwMeOo7VkTaBx1/MbAyitfwHUdLHJo4Kir9zF9Xwrj+7XTwVSO7eGgnrhzZmWfmfcPctcWhD1COOuecc6isrGTw4MHcfffdjBo1iry8PKZPn84ll1xCfn4+l19+OQB33XUX+/btY9CgQeTn5zN37lwAHnzwQc4//3zOPPNM2rdvX+dr/frXv+aOO+7gtNNOw+8/WvNxzTXX0KVLFwYPHkx+fj4zZ86sfm7y5Ml07tyZAQMG1HbKyBljonYDzgPWAd8Av7G3XQdcF7TPrViN3iuBm+o71t7+ErAC+BormbQPFcfw4cNNYznvifmm620fmllf72y0c8areWuLTdfbPjSFnm+dDiUhlXkrzTmPzzf5v/vY7Nh3xOlwYtrq1audDiGmTZkyxTz//PP17lPbewgsMrV8pka1Q7CxusrOqrHtuRqPHwIeCudYe/uPGznMiFSVOLSqyuqG2yzVxak9tfdPNGSkunhm8jAueOpzpsxcwms/O4U0t7Z3qMgMHz6crKwsHnnkkUY7p/4VRsjn16oqsEqqBauLOL13LhmpLqfDSVjdc7P40w8Hs3Trfv48e43T4ag4tHjxYubPn096euPNSKCJI0LVbRze5O5V5dl1iJ0HyrU3VRP4weD2/OSUrjz/+SZmr/zW6XBillWzohoi0vdOE0eEvPY4jmSvqirwFCECY3W0eJO48wf9GdypJbe+uZyte444HU7MycjIYM+ePZo8GsDY63FkZGSEfYzzk57EGa2qshR6ihjSuRV5zXVCvqaQ7nbx9KRh/ODJz5gycwlv/vwU0t1aRVilU6dObN++ncYc7JtMqlYADJcmjghp4zgUHSxn+fYD3Pr9vk6HklQ652TyyGVDuPafi/jDvzz8fsIgp0OKGampqWGvXqeOn1ZVRUhLHFDoscYVjNf2jSZ31oB2/Gx0D/755RY+WF5zPK1STUMTRwQCAUNlwJ6rKomnHCn0FNE5pxl92mWH3lk1ulu/35fhXVtz+1tfs7Gk1OlwVBLSxBGBqulGIHknOSzz+vl8w27G9dPR4k5JdaUwbdJQ0twpXD9jCeW+5P0So5yhiSMCxySOJK2q+nzDbioqA5w1QKupnNS+ZTMeu3wIa749xD3vrXI6HJVkNHFEwFcZnDiS81teweoimqe7OalbjtOhJL0xfdsydWwvXlu0jbcWb3c6HJVENHFEoKrEkeZOScpeVYGAoXBNMd/rm6dTX8SIm8b3ZlSPHO56dyXrig45HY5KEvrfHwFfpdUwnpOZxuGKyqQbbLR8+352l1Zob6oY4nal8OQVQ8lKd3P9jCVJW4WqmpYmjgh47SmMW2WmUhkwVCTZuuOFnmJcKcKYvnlOh6KCtG2RwZNXDmFjSSm/eWdF0n2hUU1PE0cEvHaJo3WmtdZ4sn27K/AUMaJra1pl6lrrsebUnrncPL4P7y7byasLt4U+QKnjoIkjAlVtHK2zUoHkaiDftvcIa749pL2pYtiUsb04o3cu97y/ilU7DzgdjkpgmjgiUDVqvKrEkUwN5IWeIgDGaftGzEpJER6/fAg5mWlMmbGEg+U+p0NSCUoTRwSquuNWV1Ul0SDAwjXF9MzLontultOhqHq0yU7nqUlD2bavjNvf+lrbO1RUaOKIQEV1VVVylTgOlvtYsHEP47WaKi6c1C2HX3+/L7NWfMs/v9zidDgqAWniiMDREkdVG0dyJI7560rw+Y12w40j157Rg/H923L/v1azfNt+p8NRCUYTRwS8NUocyZI4Cj3FtM5MZViX1k6HosKUkiI8PDGfts0zuH7GEg4c0fYO1Xg0cUSgZuN4MvSqqvQH+GRNMWP7tcWVopMaxpNWmWk8PXkYxYfKueWNZdreoRqNJo4IeJOwqmrxln0cKPPp2uJxakjnVtx5Xn8KPMX89bONToejEoQmjghUrTeemea25qtKgl5VBZ4i0lwpnNFHR4vHq6tO7ca5g07gT7PXsmjzXqfDUQlAE0cEqkocaa4UstPdSVHiKPQUM6pnG7LTdZXheCUi/OnSwXRq3YypM5eyp7TC6ZBUnNPEEQFf0Oy4WemuhG/j+KaklI27DzO+f1unQ1HHqUVGKk9PGsbeI15ufn05gYC2d6iG08QRgaoSR6pLyEpzJ/w4Dh0tnlgGdWzJvRcMZP66Ep6Zt8HpcFQc08QRAZ8/gAi4UoSsJKiqKlhdTP/2LejYqpnToahGcuXIzlw0pAOPzlnHf77Z7XQ4Kk5p4oiAtzJAmisFkcRPHPsOe1m0ZS9naTVVQhER/nDxiXTPzeIXryyj+FC50yGpOKSJIwJev5U4ALLTXQldVTV3bTEBg04zkoCy0t08M3k4pRU+fvHKUvza3qEipIkjAj5/oHrJ1Kw0d0I3jhd4imjbPJ1BHVo6HYqKgr4nNOf+i05kwca9PF6wzulwVJzRxBEBb2WAVLvEkchVVRWVfuav2824/u1I0dHiCevS4Z24bEQnps3dwKfrSpwOR8URTRwR8PlNdYkjO93NYW9irjv+3417Ka2o1G64SeB3Fw6ib7vm3PzaMnYdKHM6HBUnNHFEwCpxWN/As9LdBAyU+RKvuqrQU0RGagqn9cp1OhQVZc3SXDw9eRgVPj83zFxaPVZJqfpo4oiA1x8gze0CrMZxSLyJDo0xFHiKOb1XHhmpLqfDUU2gZ142D/5wMIu27OPhj9c6HY6KA5o4ImB1xz1a4oDEm+hwzbeH2LG/jLMGaDVVMrkgvwM/GtWFv8zfyJzVRU6Ho2KcJo4IHNOryk4cidYlt8D+0BjbTxNHsrnrBwMY1LEFt7y+jG17jzgdjophmjgiENyrKjtBSxwFa4oZ0rkVbZtnOB2KamIZqS6emTQcA0yduYSKysSqhlWNRxNHBGorcRxOoKnViw+Ws3zbfu1NlcS6tMnkoUvzWb79AA/MWuN0OCpGRTVxiMg5IrJWRDaIyO117DNGRJaJyCoR+TTUsSKSIyJzRGS9/bPJ1jOtOKbEYTUclyZQ4/gna4oBHS2e7M4ZdAL/e3p3XvzPZmat2OV0OCoGRS1xiIgLeBo4FxgAXCkiA2rs0wp4BrjQGDMQmBjGsbcDhcaY3kCh/bhJ+IKmHMlMS7yqqgJPER1bNaNvu+ZOh6Icdts5/RjapRW/fvNrNu8+7HQ4KsZEs8QxEthgjNlojPECrwITauwzCXjbGLMVwBhTHMaxE4B/2Pf/AVwUvUs4lre2qqoESRxlXj+fb9jNWQPaIaKjxZNdmjuFaZOG4XYJ189YQnkCjldSDRfNxNER2Bb0eLu9LVgfoLWIzBORxSLyP2Ec284YswvA/llrhbyI/ExEFonIopKSxplOwVdpjg4ATKuqqkqMxPHFht2U+wKM17U3lK1jq2Y8dtkQVu86yO8+WO10OCqGRDNx1Pa1teb8HG5gOPAD4PvA3SLSJ8xj62WMmW6MGWGMGZGX1zjrZQc3jrtdKWSkpiRMiaPAU0TzdDcju+c4HYqKIWP7teXnY3ryyldbeWfpdqfDUTEimoljO9A56HEnYGct+8w2xhw2xuwG5gP5IY4tEpH2APbPYppIcHdcsLrkJkLjeCBgKFxTzOi+edWJUakqt5zVh5Hdcrjz7ZVsKD7kdDgqBkTzU2Ih0FtEuotIGnAF8H6Nfd4DzhARt4hkAicDnhDHvg/8xL7/E/scTSK4jQMSZ4bcr3ccoORQhXbDVbVyu1J4atJQMtNcXD9jCUcSqAu6apioJQ5jTCUwFfgYKxm8boxZJSLXich19j4eYDbwNfAV8LwxZmVdx9qnfhA4S0TWA2fZj6POGHPMQk5QtSZH/P8TFXqKcKUIY/tq4lC1a9cigyeuGMr64lLuendlQs4KrcLnjubJjTGzgFk1tj1X4/FDwEPhHGtv3wOMa9xIQ/MHDMZwTOKomlo93s1ZXcTwrq1plZnmdCgqhp3eO5cbx/Xm8YL1jOrehstO6hz6IJWQtEI7TF57uunUY6qqXHE/O+72fUdY8+0hztLeVCoMN5zZm9N75XL3eyvx7DrodDjKIZo4wuSrtIrmx1RVJUAbR6HH6lswTts3VBhcKcLjVwyhZbNUrp+xhEPlPqdDUg7QxBGmCr9VsggucVi9quI7cRR4iuiRl0WPvGynQ1FxIjc7naeuHMqWPYe54+0V2t6RhDRxhMnnt/450hOoxHGo3MeCjXt00J+K2Mk92vCr7/flw6938fKCLU6Ho5qYJo4weSur2jiOjk3MSndz2OsnEIjPb1yfrd+Nz280cagGuW50T8b2zeO+Dz2s2H7A6XBUE9LEEaaqtZhTj+mOa007ciRO5/EpWF1Eq8xUhnVp5XQoKg6lpAiPXjaE3Ow0rp+5mANl2t6RLDRxhKmqxFGzcRzic6LDSn+AT9YWc2bftrhd+megGqZ1VhrTJg9j1/5ybn1jubZ3JAn9xAhTbd1xs+N4+dglW/ez/4hP195Qx21Yl9bcfm4//r26iL99vsnpcFQT0MQRJp9d4qjZOA7xWeIo8BSR6hLO6J3rdCgqAfzv6d05e0A7HvxoDYu37HM6HBVlmjjCVNcAQIjPEkeBp4hRPdrQPCPV6VBUAhARHpqYT/tWGUyduYS9h71Oh6SiSBNHmKoax2tOOQLE3ejxjSWlbCw5rL2pVKNq2SyVZyYNZ0+pl1++vixuexuq0DRxhKm6O24CVFXpaHEVLSd2asndFwxg3toSnpv/jdPhqCjRxBEmrz0AMK2WxvF4m+hwjqeIfic0p1PrTKdDUQnoRyd34YL8Djz88VoWbNzjdDgqCjRxhClRuuPuO+xl8ZZ9nKW9qVSUiAgPXHIi3dpk8YtXllJyqMLpkFQj08QRpuo2jqASR2ZqVeN4/LRxzFtXjD9gGKftGyqKstPdPD15GAfKfNz02lL82t6RUDRxhOloG8fRKUdSUoSsNFdclTgKPMXkNU9ncMeWToeiElz/9i24b8IgvtiwhycL1zsdjmpEmjjC5KulOy7E10SH3soAn64tYVy/tqSkSOgDlDpOE0d04ofDOvHkJ+v5bH2J0+GoRqKJI0wVtbRxQHxNrf7Vpr2UVlRqN1zVZESE+y4aSO+22dz06jKKDpY7HZJqBJo4wlTbOA6AzPT4qaoq8BSR7k7htF46Wlw1ncw0N89MHkaZz88NM5dSaf8vqfiliSNM3soA7hT5ThVPVpo7LgYAGmOYs7qIM3rn0sye1VepptKrbXMeuOREvtq8l0fmrHM6HHWcNHGEyecPHDP4r0q8VFWtLTrEjv1lWk2lHDNhSEcmndyFZ+d9wydripwORx0HTRxh8vnNMV1xq1iLOcV+4ihYbf2jntlPR4sr5/z2/AEMaN+Cm19bzvZ9R5wORzVQWIlDRN4SkR+ISNImmorK2ksc8dKrqsBTTH7nVrRtkeF0KCqJZaS6eGbyMPwBw9SZS6u7uav4Em4ieBaYBKwXkQdFpF8UY4pJPn+A9FpKHNnprpivqio+VM6ybfsZr6UNFQO65Wbx50sHs2zbfh78aI3T4agGCCtxGGMKjDGTgWHAZmCOiPxHRK4WkaSYl9tbGThm8F+VrHQ35b5ATPcUmbvGmtRQF21SseK8E9tz1andeOGLTcxeucvpcFSEwq56EpE2wFXANcBS4AmsRDInKpHFGJ8/UGsbR9VEh7G87vic1cV0bNWMfic0dzoUpardeV5/8ju34tY3v2bLnsNOh6MiEG4bx9vAZ0AmcIEx5kJjzGvGmBuA7GgGGCu89bRxQOxOdFju8/P5hhLG92+LiI4WV7EjzZ3CtCuHkiLClJlLKI/hL1/qWOGWOKYZYwYYYx4wxhxTrjTGjIhCXDHHW0eJI9YTxxcbdlPuC+ikhiomdc7J5NHL8lm54yD3/2u10+GoMIWbOPqLSKuqByLSWkSuj05IsamuEkd2emzPkFvgKSY73c3JPXKcDkWpWo3r347/G92Dlxds5b1lO5wOR4Uh3MRxrTFmf9UDY8w+4NqoRBSjfP7Ad6YbAWvkOMRmiSMQMBR6ihjdJ5d0t44WV7HrV9/vy4iurbnj7RVsKC51OhwVQriJI0WCKshFxAWkRSek2BSqqioWu+Su2HGA4kMVOlpcxbxUVwpPTRpKRqqLKTOWUOaNzRK8soSbOD4GXheRcSJyJvAKMDt6YcUeX6WpszsuxGaJo9BTRIrA2L46fkPFvvYtm/H45UNYV3yIe95f6XQ4qh7hJo7bgE+AnwNTgELg19EKKhZZJY7vVvdk2W0csZg45niKGdE1h9ZZSVU4VHFsdJ88bhjbi9cXbeeNRducDkfVIdwBgAFjzLPGmEuNMT80xvzFGJNUZcm6BgBmV1dVxdbbsWN/GZ5dBxk/QEsbKr7cOL4Pp/Row93vrWTtt4ecDkfVItxxHL1F5E0RWS0iG6tu0Q4ultQ15UizVBcpEnsljkKPNamhdsNV8caVIjxx5RCy01P5+YzFMfe/pcKvqvo71nxVlcBY4J/AS9EKKhZ565hWXUTISou9qdULPMX0yM2iZ15SjM9UCaZt8wyevHIIm3cf5s53VmCMcTokFSTcxNHMGFMIiDFmizHmXuDM6IUVe3yVtXfHhdibIbe0opIF3+xhXH+tplLx69SeufzyrD68t2wnM7/a6nQ4Kki4iaPcnlJ9vYhMFZGLgaT6VPL6A6TWUlUFVgN5LK3J8dm6Erz+gHbDVXHv+jG9GN0nj999sJqVOw44HY6yhZs4bsKap+oXwHDgR8BPQh0kIueIyFoR2SAit9fy/BgROSAiy+zbb4Oeu1FEVorIKhG5KWj7vSKyI+iY88K8hgYzxlgLOdVR4shOj63lY+d4imjZLJXhXVs7HYpSxyUlRXj88iHkZKYxZeYSDpb7nA5JEUbisAf7XWaMKTXGbDfGXG33rFoQxnFPA+cCA4ArRWRALbt+ZowZYt9+bx87CGtk+kggHzhfRHoHHfNY0DGzwrrS4+C1p0yvbQAgxFZVlT9gmLummDP7tcVdR6JTKp7kZKXx9OSh7NhXxm1vfq3tHTEg5CeL3e12ePDI8TCNBDYYYzYaY7zAq8CEMI/tDywwxhwxxlQCnwIXR/j6jcbnt/5Q62vjiJXG8SVb97HviE/bN1RCGd41h9vO6cdHK7/lxf9sdjqcpBfuV9KlwHsi8mMRuaTqFuKYjkDwCJ7t9raaThGR5SLykYgMtLetBEaLSBsRyQTOAzoHHTNVRL4WkRdEpNb6GBH5mYgsEpFFJSUlYV1kXaqWt6xtHAfYVVUx0sZR4Cki1SWM7pPndChKNaprzujO+P7t+OMsD0u37nM6nKQWbuLIAfZg9aS6wL6dH+KY2j5la5YxlwBdjTH5wFPAuwDGGA/wJ6xFomYDy7G6AoPVLbgnMATYBTxS24sbY6YbY0YYY0bk5R3fh6jPrqqqt3E8Rto4ClYXcXL3NrTISIqFGVUSEREemZhPuxYZTJ25lP1HvE6HlLTCHTl+dS23n4Y4bDvHlhI6ATtrnPegMabUvj8LSBWRXPvx34wxw4wxo4G9wHp7e5Exxm+MCQB/xaoSi6qqEkesV1Vt2n2Yb0oOM16rqVSCapmZytOThlF8qJxbXl9OIKDtHU4Id+T43+1qoWNuIQ5bCPQWke4ikgZcAbxf47wnVLWdiMhIO5499uO29s8uwCVYEysiIu2DTnExVrVWVIVsHE9z460MVJdMnKKjxVUyyO/cirt+MIDCNcVM/yypJrCIGe4w9/sw6H4G1gf2zjr2BcAYUykiU7Fm1nUBLxhjVonIdfbzzwGXAj8XkUqgDLjCHO0y8Za9zrkPmGKvAQLwZxEZglXttRn4vzCvocHCKXGANe1Iq0znJhScs7qIfic0p3NOpmMxKNUU/ueUrny1aS8PfbyW4V1bc1I3XaisKYWVOIwxbwU/FpFXgIIwjpsFzKqx7bmg+9OAaXUce0Yd238cRsiNqrqNo85xHFWrADqXOPYf8bJoyz5+/r2ejry+Uk1JRHjwhyeyaucBps5cwqxfnEGb7HSnw0oaDe3o3xvo0piBxDJfGOM4AEcbyOetLcEfMNoNVyWN5hmpPDN5OPuO+LjptWX4tb2jyYTbxnFIRA5W3YAPsNboSAoVlfWXOGJhFcACTxG52enkd2rlWAxKNbUBHVrwuwsH8tn63Tw9d4PT4SSNcKuqmkc7kFhWPQCwjhJHtsOrAHorA3y6toTzTmxPSkqk4zSVim9XnNSZrzbt5bGCdQzv2prTeuU6HVLCC7fEcbGItAx63EpELopaVDEmZON4mrOJY+HmvRyqqGT8AO1NpZKPiHD/RYPomZfNja8upfhgudMhJbxw2zjuMcZUT01pjNkP3BOViGJQqDaO6hKH15k2jjmri0h3p3C6ftNSSSor3c2zk4dxuMLPDa8spdLhrvGJLtzEUdt+4XbljXuhphxxct1xYwyFa4o4vVcuzdK+uya6Usmid7vm/OHiQfx3014eL1jvdDgJLdzEsUhEHhWRniLSQ0QeAxZHM7BYEs7suOBM4/i6olK27S3TQX9KAZcM68QVJ3Vm2twNzF1b7HQ4CSvcxHED4AVeA17HGqw3JVpBxZpQbRzp7hTcKeJIiaOgerS4dsNVCuDeCwfS74Tm/PK1ZezcX+Z0OAkp3LmqDhtjbq+aNNAYc6cx5nC0g4sVoQYAiohja3IUeIoY3Kkl7VpkNPlrKxWLMlJdPDN5GN7KAFNnLnF8KqBEFG6vqjki0irocWsR+ThqUcWY6hJHHVVVYDWQlzbxAMCSQxUs27Zfl4hVqoYeedk8+MPBLNm6nz/PXuN0OAkn3KqqXLsnFQD2vFFJUzcSqsQBkJnmavISx9w1xRiDJg6lanFBfgf+55Su/PWzTfx71bdOh5NQwk0cAXuWWgBEpBvfXVsjYYXqVQX28rFNvJjTHE8RHVpm0L99Uo/PVKpOv/lBf07s2JJb3ljOtr1HnA4nYYSbOH4DfC4iL4nIS1hLud4RvbBii9dvSHOlUN/qudlNvCZHuc/P5+t3M35Au3rjUiqZpbut9g6AKTOXUFEZGwuuxbtwG8dnAyOAtVg9q27B6lmVFHz+QL3tG1C1CmDTJY7/fLObMp9fu+EqFULnnEwemZjP19sP8Md/eZwOJyGENYhPRK4BbsRaxW8ZMAr4Emsp2YTnrQzUW00FdlVVEzaOF3iKyUpzMaqHrkOgVChnDzyBa07vzvOfb+Kk7jmcP7iD0yHFtXCrqm4ETgK2GGPGAkOBkqhFFWPCKXE0ZVWVMYZCTxGj++SR7tbR4kqF47Zz+zGsSytuf2sFG0tKnQ4nroWbOMqNMeUAIpJujFkD9I1eWLHFKnGEqqqyxnEcXcAwelbuOEjRwQrtTaVUBFJdKUybNIxUl3D9jCWU+7S9o6HCTRzb7XEc7wJzROQ9Qiwdm0i8YZY4KgOmeu2OaJrjKSJFYGy/pOkRrVSj6NCqGY9ePoQ13x7i3vdXOR1O3Ap3PY6L7bv3ishcoCUwO2pRxRhvZaDO6UaqZNkTDB7x+slIjW71UaGniOFdW5OT5dz65krFq7F92zJlbE+envsNI7vncMmwTk6HFHciXjrWGPOpMeZ9Y4w3GgHFovB6VTXNmhw795exaudB7U2l1HG4eXwfTu6ew2/eWcn6okNOhxN3GrrmeFLx+kO3cWQ30Qy5hfakhtq+oVTDuV0pPHXlULLSXfx8xhKONPHg3XiniSMMvkoTVndciH6Jo8BTTLc2mfTMy4rq6yiV6Nq2yOCJK4byTUkpd72zskk6tiQKTRxhqPAHSAvR7bUp1uQorajky2/2ML6/jhZXqjGc1iuXm8b14e2lO3ht4Tanw4kbmjjC4KsMkBaixFG9fGwUBwF+vr4Erz+ga4sr1YimntmLM3rn8tv3V7Fq54HQByhNHOEIpztuZlr0l4+ds7qYls1SGdG1ddReQ6lk40oRHrt8CK0zU5kyYwmHyn1OhxTzNHGEwRcDjeP+gGHu2mLG9s3DHSIWpVRkcrPTeerKYWzbV8btb63Q9o4Q9BMoDL5wxnFEuXF86dZ97D3s1W64SkXJyO453Pr9vvxrxS5eWrDF6XBimiaOMHj9AVJDVFWluVNIc6VQGqVufQWeYtwpwvf65kXl/Eop+NkZPRjXry33fbia5dv2Ox1OzNLEEYZwRo5DdKdWL/AUcXKPHFpkpEbl/EopSEkRHrksn7bNM5gycwkHjmh7R200cYQhnMZxiN7U6pt3H2ZDcakO+lOqCbTKTGPapKEUHSznljeWa3tHLTRxhMFnrwAYSrSmVi/Q0eJKNamhXVpzx7n9KfAU8fxnm5wOJ+Zo4gjBHzD4AyZkryqwShzRmLqgwFNE33bN6ZyT2ejnVkrV7urTunHOwBN4cPYaFm/Z63Q4MUUTRwg+vzVNerhVVaWNXFV14IiPhZv3Ma6/TqGuVFMSEf48cTAdWzVj6syl7D2cNPO6hqSJI4Sq9TVCzVUFkB2FxvF564rxB4yOFlfKAS0yUnlm8jD2HPZy82vLCAS0vQM0cYQUUYkjzd3oiaPAU0xudhpDOrVq1PMqpcIzqGNLfnv+AD5dV8Kzn37jdDgxQRNHCF67xBFed9zGbRz3+QPMW1vMmf3akpKikxoq5ZTJJ3fhwvwOPPLvtXz5zR6nw3GcJo4Qqkoc4TSOZzfyuuMLN+3lUHml9qZSymEiwh8vOZFuuVn84tWlFB8qdzokR2niCCGSqqrMdBcBA+W+xll3fI6niDR3Cqf3zm2U8ymlGi473c0zk4dxqNzHja8sw5/E7R1RTRwico6IrBWRDSJyey3PjxGRAyKyzL79Nui5G0VkpYisEpGbgrbniMgcEVlv/4zqVLFHG8fDK3FA40x0aIyhwFPE6b1yyUwLa2l4pVSU9TuhBfdNGMSXG/fwRME6p8NxTNQSh4i4gKeBc4EBwJUiMqCWXT8zxgyxb7+3jx0EXAuMBPKB80Wkt73/7UChMaY3UGg/jhqf3/pWkR5m4zg0zkSH64tL2ba3TLvhKhVjJo7ozMThnXhq7gbmrytxOhxHRLPEMRLYYIzZaIzxAq8CE8I8tj+wwBhzxBhTCXwKXGw/NwH4h33/H8BFjRfyd3kjKHE05iqAVaPFx/XT9g2lYs3vJwyiT9vm3PTaMr49kHztHdFMHB2B4LUYt9vbajpFRJaLyEciMtDethIYLSJtRCQTOA/obD/XzhizC8D+WetXchH5mYgsEpFFJSUN/1YQSRtHdiNOrV6wuogTO7bkhJYZx30upVTjapbm4unJwyj3+bnhlSXVnxPJIpqJo7b+ozVbk5YAXY0x+cBTwLsAxhgP8CdgDjAbWA5E9GlsjJlujBlhjBmRl9fwqci9EQwAzEq3VwE8zmlHdpdWsHTbfu1NpVQM69U2mwcuOZGFm/fx8L/XOh1Ok4pm4tjO0VICQCdgZ/AOxpiDxphS+/4sIFVEcu3HfzPGDDPGjAb2Auvtw4pEpD2A/bM4iteAtwEljuOdduSTNcUYg7ZvKBXjJgzpyOSTu/CXTzdSsLrI6XCaTDQTx0Kgt4h0F5E04Arg/eAdROQEERH7/kg7nj3247b2zy7AJcAr9mHvAz+x7/8EeC+K1xDxAECAI8dZVVWwuoj2LTMY2KHFcZ1HKRV9d58/gIEdWnDLG8vZtveI0+E0iaglDrtReyrwMeABXjfGrBKR60TkOnu3S4GVIrIceBK4whwdPfeWiKwGPgCmGGP22dsfBM4SkfXAWfbjqIl0kkM4vsbxcp+fz9bvZlz/ttg5VSkVwzJSXTwzeRiBgGHqK0urv2wmsqgOELCrn2bV2PZc0P1pwLQ6jj2jju17gHGNGGa9IupVlWa3cRxHVdWX3+yhzOfX9g2l4kjXNlk8NHEw1728hAc+8nDPBQNDHxTHdOR4CJFMOeJ2pZCRmnJcjeMFniIy01yM6tGmwedQSjW9cwa156endefvX2zmoxW7nA4nqjRxhFA1cjycqio4vlUAjTEUeooZ3TuPjFRXg86hlHLO7ef2I79zK3795tds3n3Y6XCiRhNHCFUjx8NpHIeqdccbljhW7TzItwfLde0NpeJUmjuFpycNJSVFuH7GEsp9jbuwW6zQxBFCJI3jAJnHsSbHnNVFiMDYvg0fd6KUclan1pk8elk+q3cd5PcfrnY6nKjQxBGCtzJAioArzPUwstNdDa6qKlxTxPAurWmTnd6g45VSsWFc/3Zc972ezPzvVt5dusPpcBqdJo4QfP5A2KUNqKqqirx4uutAGSt3HGSc9qZSKiH86uw+jOyWw53vrGBDcanT4TQqTRwhVFQGwupRVaWhbRyFHmsA/FkDdLS4UonA7UrhySuH0izVxfUzFlPmTZz2Dk0cIfj8gbCmVK+SndawXlUFniK6tsmkZ152xMcqpWLTCS0zePyKIawvLuXu91Y6HU6j0cQRgrcJShyHKyr5z4Y9jO/fTkeLK5Vgzuidxw1n9ubNxdt5fdG20AfEAU0cIUTaxpGd7uKw108ggmUlP1u/G68/oJMaKpWgbhzXm1N7tuHud1fi2XXQ6XCOmyaOELz+yEscAGUR9N8u8BTRIsPNSd1yIo5PKRX7XCnCE1cMpUWzVKbMWNIoi705SRNHCN5K06DEEW51lT9gmLummDF920b0Okqp+JLXPJ2nrhzK5j2HuePtFRydzzX+6CdVCN6Iq6oimyF32bZ97Dns1dHiSiWBUT3acMvZfflg+U5e/u9Wp8NpME0cIfgqA6SFsfpflaMljvCqqgo8xbhThO/10dHiSiWDn3+vJ2P65nHfB6tZueOA0+E0iCaOECItcVQtHxtuiaNgdREju+fQsllqg+JTSsWXlBTh0cuG0CY7jetnLOFAmc/pkCKmiSMEX4SN49kRtHFs2XOY9cWluvaGUkkmJyuNaZOGsnN/Gb9+c3nctXdo4gjBWxkIe2ZcsCY5BMJak6PAHi2uiUOp5DO8aw63n9uPj1cV8cIXm50OJyKaOELw+gOkRqlxvNBTRJ922XRpk9ng+JRS8et/T+/OWQPa8cAsD0u27gt9QIzQxBGCzx8gPaLuuFXLx9afOA4c8fHfTXt1UkOlkpiI8PCl+bRvlcHUGUvYd9jrdEhh0cQRQsRTjqRVlTjq71U1b10x/oDRaiqlklzLzFSenjSM3aVefvn6sohmnXCKJo4QfH4TUa+qlBQhM80VssRR6CmmTVYaQzq3Os4IlVLxbnCnVtx9fn/mri3hL/M3Oh1OSJo4Qoi0xAGhJzr0+QPMXVvMmf3ahr1AlFIqsf1oVFfOH9yeh/+9lv9u3ON0OPXSxBFCpOM4wGogr69xfOHmvRwqr9T2DaVUNRHhgUtOpEtOJje8spTdpRVOh1QnTRz1MMbY3XEjKxVkpbs4Us+iLQWri0lzp3BG79zjDVEplUCaZ1jtHQfKfNz06jL8MdreoYmjHpX2Ly3iqqp6FnMyxlC4pohTe7apnp5EKaWqDOjQgt9PGMjnG3bz1CfrnQ6nVpo46uGtDAA0qKqqrjaODcWlbNlzRHtTKaXqdNmIzlwyrCNPFK7n8/W7nQ7nOzRx1MPntxJHYzaOV40W10WblFJ1ERHuv2gQvfKyuem1pRQdLHc6pGNo4qhHQ0scWenuOsdxFHiKGNSxBe1bNjvu+JRSiSszzc2zPxrG4Qo/N7yylEr7i2ws0MRRD6/9i4pkriqwl4+tpcSxp7SCJVv3aTWVUiosvdo254+XDOKrTXt5dM46p8OppomjHj6/1TgeaYkjM81Nmc//nR4Rn6wpxhid1FApFb6Lh3biypGdeWbeN8xdU+x0OIAmjnpVVVVF2sZRPbV6jRlyCz3FnNAig4EdWjROgEqppHDPBQPp374FN7++jB37y5wORxNHfaoaxxvSxgHHTnRY7vMzf30J4/q3RURHiyulwpeR6uKZycOo9BumzlxS/aXWKZo46lFRXeKIfAAgHJs4vty4hyNev64trpRqkO65Wfzph4NZunU/f5q9xtFYNHHUo6EljqNrchztWVXoKSIzzcUpPdo0XoBKqaTyg8HtuerUbvzt803MXvmtY3Fo4qhHdXfcBozjgKMlDmMMhZ5izuidS0aqq3GDVEollTvO60d+p5bc+uZytu454kgMmjjqcfwlDitxrNp5kF0HynVSQ6XUcUt3u5g2aRgCXD9zMeW++tf+iQZNHPVoaK+qqhLHEbtXVYGnCBE4s5+OFldKHb/OOZk8ctkQVu44yB/+5Wny19fEUQ9vg6ccsaqjqto4Cj3FDO3citzs9MYNUCmVtM4a0I6fje7BSwu28P7ynU362lFNHCJyjoisFZENInJ7Lc+PEZEDIrLMvv026LmbRWSViKwUkVdEJMPefq+I7Ag65rxoxV9V4khvYFXV4YpKvj1QzoodB7Q3lVKq0d36/b4M79qaO976mm9KSpvsdaOWOETEBTwNnAsMAK4UkQG17PqZMWaIffu9fWxH4BfACGPMIMAFXBF0zGNBx8yK1jVUjRyPtMTRLNVFiliJo3BNEaCjxZVSjS/VlcK0SUNJc6cwZcYSyupZB6gxRbPEMRLYYIzZaIzxAq8CEyI43g00ExE3kAk0bVkM8FZav4RIG8dFpHpNjoLVRXTJyaR32+xohKiUSnLtWzbjscuHsLboEPe+v6pJXjOaiaMjsC3o8XZ7W02niMhyEflIRAYCGGN2AA8DW4FdwAFjzL+DjpkqIl+LyAsi0rq2FxeRn4nIIhFZVFJS0qALOFriiHykd1a6m5JDFXzxzR7G92+no8WVUlEzpm9bpozpxWuLtvHm4u1Rf71oJo7aPilrroO4BOhqjMkHngLeBbCTwQSgO9AByBKRH9nHPAv0BIZgJZVHantxY8x0Y8wIY8yIvLy8Bl2At4HdcQEy013MW1uCtzLAeF17QykVZTeN782oHjnc9e4K1n57KKqvFc3EsR3oHPS4EzWqm4wxB40xpfb9WUCqiOQC44FNxpgSY4wPeBs41d6vyBjjN8YEgL9iVYlFRXV33JTI36bsdKuqqnmGm5O65zR2aEopdQy3K4UnrxhKdnoq189YXOdico0hmoljIdBbRLqLSBpW4/b7wTuIyAli1+GIyEg7nj1YVVSjRCTTfn4c4LH3ax90iouBldG6AJ8/QKpLSElpQFVVmtWzakzfthE3riulVEO0bZHBk1cOYdPuw9z5zgqMqVnJ0zjcUTkrYIypFJGpwMdYvaJeMMasEpHr7OefAy4Ffi4ilUAZcIWxrvS/IvImVlVWJbAUmG6f+s8iMgSr2msz8H/RugZvZaDBH/pVgwC1mkop1ZRO7ZnLzeP78MicdZzcvQ2TTu7S6K8RtcQB1dVPs2psey7o/jRgWh3H3gPcU8v2HzdymHXy+QMNat8AaxVAV4owpo8mDqVU05oythcLt+zj3g9WMbhTSwZ1bNmo549q4oh3/du3oNzXsHnvJ53cleFdW9MyM7WRo1JKqfqlpAiPXZbPTa8ti3gAczgkWnVgsWTEiBFm0aJFToehlFJxRUQWG2NG1NyurbZKKaUioolDKaVURDRxKKWUiogmDqWUUhHRxKGUUioimjiUUkpFRBOHUkqpiGjiUEopFZGkGAAoIiXAlgYengvsDmNbuMcmsmS73sam75+KhuP5u+pqjPnOuhRJkTiOh4gsqjlysrZt4R6byJLtehubvn8qGqLxd6VVVUoppSKiiUMppVRENHGENj3MbeEem8iS7Xobm75/Khoa/e9K2ziUUkpFREscSimlIqKJQymlVEQ0cdRBRF4QkWIRWRm0rbOIzBURj4isEpEb6zneJSJLReTDpom4adX2/tjbbxCRtfb782en4otlIpIhIl+JyHL7ffqdvf0hEVkjIl+LyDsi0srhUFWcEZFWIvKm/XfkEZFTovF3pYmjbi8C59TYVgncYozpD4wCpojIgDqOvxHwRC88x71IjfdHRMYCE4DBxpiBwMMOxBUPKoAzjTH5wBDgHBEZBcwBBhljBgPrgDucC1HFqSeA2caYfkA+1mdQo/9daeKogzFmPrC3xrZdxpgl9v1DWL+UjjWPFZFOwA+A55sgVEfU9v4APwceNMZU2PsUN3lgccBYSu2HqfbNGGP+bYyptLcvADo5EqCKSyLSAhgN/A3AGOM1xuyPxt+VJo4GEpFuwFDgv7U8/TjwayDQhCHFgj7AGSLyXxH5VEROcjqgWGVXZS4DioE5xpiaf0c/BT5q8sBUPOsBlAB/t6vJnxeRrBr7NMrflSaOBhCRbOAt4CZjzMEaz50PFBtjFjsSnLPcQGusarxbgddFRJwNKTYZY/zGmCFY3/5GisigqudE5DdY1aIzHApPxSc3MAx41hgzFDgM3F71ZGP+XWniiJCIpGIljRnGmLdr2eU04EIR2Qy8CpwpIi83YYhO2g68bVfFfIVV4sp1OKaYZozZD8zDbi8SkZ8A5wOTjQ6yUpHZDmwPKr2+iZVIGv3vShNHBOxvz38DPMaYR2vbxxhzhzGmkzGmG3AF8Ikx5kdNGKaT3gXOBBCRPkAaOtvrd4hIXlXPFhFpBowH1ojIOcBtwIXGmCMOhqjikDHmW2CbiPS1N40DVkfj78rdGCdJRCLyCjAGyBWR7cA9wFrgx8AKu34a4E5jzCxHgnRQHe/PC8ALdhddL/AT/dZcq/bAP0TEhfXl7XVjzIcisgFIB+bYNXwLjDHXORinij83ADNEJA3YCFwNLKSR/650yhGllFIR0aoqpZRSEdHEoZRSKiKaOJRSSkVEE4dSSqmIaOJQSikVEU0cKunZM4pe73QcoYjITSKS6XQcSmniUApaAY4nDrHU9z95ExBR4hARHaulGp0mDqXgQaCniCyz1y64VUQW2usXVK2V0c1e0+B5EVkpIjNEZLyIfCEi60VkpL3fvSLykoh8Ym+/tupF6jmvR0SeAZYAnUXkWRFZVGOtjl8AHYC5IjLX3lYadO5LReRF+/6LIvKovd+fRKSniMwWkcUi8pmI9GuC91QlMP02opQ1EdwgY8wQETkbuBQYCQjwvoiMBrYCvYCJwM+wRuNOAk4HLgTuBC6yzzcYa6LHLGCpiPwLGAT0ruO8fYGrjTHXgzUZnTFmrz2yvFBEBhtjnhSRXwJjjTHhTOPSBxhvjPGLSCFwnTFmvYicDDyDPTWMUg2hiUOpY51t35baj7OxPvC3ApuMMSsARGQVUGiMMSKyAugWdI73jDFlQJn9rX8kVoKp67xbjDELgo6/TER+hvX/2R4YAHwd4XW8YSeNbOBU4I2giYrTIzyXUsfQxKHUsQR4wBjzl2M2WuuvVARtCgQ9DnDs/1LNeXxMiPMeDnrcHfgVcJIxZp9d/ZRRR6zBr1Nzn6pzpgD77SnclWoU2sahFBwCmtv3PwZ+an9TR0Q6ikjbCM83Qax1xdtgTQS5MILztsD60D8gIu2Ac+uIE6BIRPrbDeoX1xaIvV7MJhGZaL+uiEh+hNej1DG0xKGSnjFmj93IvRJrdbSZwJd21U4p8CPAH8EpvwL+BXQB7jPG7AR2ikj/UOc1xiwXkaXAKqzZTb8Ieno68JGI7DLGjMVqm/kQ2AasxKr+qs1k4FkRuQtrmdpXgeURXI9Sx9DZcZVqRCJyL1BqjHnY6ViUihatqlJKKRURLXEopZSKiJY4lFJKRUQTh1JKqYho4lBKKRURTRxKKaUioolDKaVURP4fsxC4mPj3zEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accnew = [i * 6 for i in acc6]\n",
    "plt.plot(DI_TEMPERATURE,accnew)\n",
    "plt.xticks(DI_TEMPERATURE)\n",
    "plt.title('Test accuracy vs. tempreture curve')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('temperature')\n",
    "plt.legend(['accuracy'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNrH_1emRbGA"
   },
   "source": [
    "# Train student from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "HjospsxIRbQ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 96.46%\n",
      "Epoch 2: Class_accuracy: 97.80%\n",
      "Epoch 3: Class_accuracy: 97.95%\n",
      "Epoch 4: Class_accuracy: 98.07%\n",
      "Epoch 5: Class_accuracy: 98.14%\n",
      "Epoch 6: Class_accuracy: 97.50%\n",
      "Epoch 7: Class_accuracy: 98.14%\n",
      "Epoch 8: Class_accuracy: 98.00%\n",
      "Epoch 9: Class_accuracy: 98.11%\n",
      "Epoch 10: Class_accuracy: 97.48%\n",
      "Epoch 11: Class_accuracy: 98.10%\n",
      "Epoch 12: Class_accuracy: 97.85%\n"
     ]
    }
   ],
   "source": [
    "# Build fully connected student.\n",
    "# fc_model_no_distillation\n",
    "s_model_no_distillation = tf.keras.Sequential()\n",
    "\n",
    "# your code start from here for step 7\n",
    "s_model_no_distillation.add(tf.keras.Input(shape=(28,28,1)))\n",
    "s_model_no_distillation.add(Flatten())\n",
    "s_model_no_distillation.add(Dense(784, activation='relu'))\n",
    "s_model_no_distillation.add(Dense(784, activation='relu'))\n",
    "s_model_no_distillation.add(Dense(10))\n",
    "\n",
    "\n",
    "\n",
    "#@test {\"output\": \"ignore\"}\n",
    "DISTILLATION_TEMPERATURE = 4\n",
    "def compute_plain_cross_entropy_loss(images, labels):\n",
    "  \"\"\"Compute plain loss for given images and labels.\n",
    "\n",
    "  For fair comparison and convenience, this function also performs a\n",
    "  LogSumExp over subclasses, but does not perform subclass distillation.\n",
    "\n",
    "  Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Scalar loss Tensor.\n",
    "  \"\"\"\n",
    "  # your code start from here for step 7\n",
    "\n",
    "  student_subclass_logits = s_model_no_distillation(images, training=True)\n",
    "  cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, student_subclass_logits))\n",
    "  \n",
    "  return cross_entropy_loss\n",
    "\n",
    "\n",
    "train_and_evaluate(s_model_no_distillation, compute_plain_cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq3JTpQ4RuhR"
   },
   "source": [
    "# Comparing the teacher and student model (number of of parameters and FLOPs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLOPs Code refer to Reference[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "4V8GB2yRRuxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/24.17m flops)\n",
      "  sequential/conv2d_1/Conv2D (21.23m/21.23m flops)\n",
      "  sequential/dense/MatMul (2.36m/2.36m flops)\n",
      "  sequential/conv2d/Conv2D (389.38k/389.38k flops)\n",
      "  sequential/max_pooling2d/MaxPool (86.53k/86.53k flops)\n",
      "  sequential/conv2d_1/BiasAdd (36.86k/36.86k flops)\n",
      "  sequential/max_pooling2d_1/MaxPool (36.86k/36.86k flops)\n",
      "  sequential/conv2d/BiasAdd (21.63k/21.63k flops)\n",
      "  sequential/dense_1/MatMul (2.56k/2.56k flops)\n",
      "  sequential/dense/BiasAdd (128/128 flops)\n",
      "  sequential/dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 0.0242 G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:36:09.742820: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-04-02 14:36:09.742970: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-02 14:36:09.745357: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code start from here for step 8\n",
    "# pip install keras-flops if needed\n",
    "# Calculae teacher FLOPS\n",
    "flops_t = get_flops(teacher_model, batch_size=1)\n",
    "print(f\"FLOPS: {flops_t / 10 ** 9:.03} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.48m flops)\n",
      "  sequential_1/dense_2/MatMul (1.23m/1.23m flops)\n",
      "  sequential_1/dense_3/MatMul (1.23m/1.23m flops)\n",
      "  sequential_1/dense_4/MatMul (15.68k/15.68k flops)\n",
      "  sequential_1/dense_2/BiasAdd (784/784 flops)\n",
      "  sequential_1/dense_3/BiasAdd (784/784 flops)\n",
      "  sequential_1/dense_4/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 0.00248 G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:38:40.154177: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-04-02 14:38:40.154293: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-02 14:38:40.165387: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flops_sKD = get_flops(student_model, batch_size=1)\n",
    "print(f\"FLOPS: {flops_sKD / 10 ** 9:.03} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.48m flops)\n",
      "  sequential_5/dense_14/MatMul (1.23m/1.23m flops)\n",
      "  sequential_5/dense_15/MatMul (1.23m/1.23m flops)\n",
      "  sequential_5/dense_16/MatMul (15.68k/15.68k flops)\n",
      "  sequential_5/dense_14/BiasAdd (784/784 flops)\n",
      "  sequential_5/dense_15/BiasAdd (784/784 flops)\n",
      "  sequential_5/dense_16/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPS: 0.00248 G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 14:39:13.883028: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-04-02 14:39:13.883136: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-02 14:39:13.884437: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flops_sNKD = get_flops(s_model_no_distillation, batch_size=1)\n",
    "print(f\"FLOPS: {flops_sNKD / 10 ** 9:.03} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher flops = FLOPS: 0.0242 G\n",
      "student with KD flops = FLOPS: 0.00248 G\n",
      "student without KD flops = FLOPS: 0.00248 G\n"
     ]
    }
   ],
   "source": [
    "print('teacher flops = FLOPS: 0.0242 G')\n",
    "print('student with KD flops = FLOPS: 0.00248 G')\n",
    "print('student without KD flops = FLOPS: 0.00248 G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b5yNhJfRu-7"
   },
   "source": [
    "# XAI method to explain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "yFgp5kA5RvID"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 9\n",
    "def grad_cam(input_model, image, layer_name):\n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "#     y_c = input_model.output\n",
    "    y_c = tf.nn.softmax(input_model.output)\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    feedforward1 = keras.models.Model([input_model.input], [conv_output, y_c])\n",
    "    with tf.GradientTape() as tape:\n",
    "        ff_results=feedforward1([image])\n",
    "        all_fmap_masks, predictions = ff_results[0], ff_results[-1]\n",
    "        loss = predictions[:, cls]\n",
    "    grads_val = tape.gradient(loss, all_fmap_masks)\n",
    "    if len(image.shape)==3:\n",
    "        axis=(0, 1)\n",
    "    elif len(image.shape)==4:\n",
    "        axis=(0, 1, 2)\n",
    "    weights = np.mean(grads_val, axis=axis)\n",
    "    cam = np.dot(all_fmap_masks[0], weights)\n",
    "    #print (cam)\n",
    "    H,W= image.shape[1:3]\n",
    "    cam = np.maximum(cam, 0)\n",
    "    #cam = resize(cam, (H, W))\n",
    "    cam = zoom(cam,H/cam.shape[0])\n",
    "    #cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GradCAM and set the input as image[2]\n",
    "explanation_map_GradCAM = grad_cam(teacher_model, np.expand_dims(image[2], axis=0), 'max_pooling2d_1')\n",
    "explanation_map_GradCAM -= explanation_map_GradCAM.min()\n",
    "explanation_map_GradCAM /= explanation_map_GradCAM.max()+10e-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Explanation map (Grad-CAM) - alpha=0.5')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "# plt.imshow(image[2])\n",
    "plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM only) - alpha=0.5')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(image[2])\n",
    "# plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM) - alpha=0.5')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(image[2])\n",
    "plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM) - alpha=0.5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### student_model with KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"student\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 28, 1, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xq/dngxcprn24qdwh7f57xlry5r0000gn/T/ipykernel_28507/3683939055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplanation_map_GradCAM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_modelKD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flatten_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexplanation_map_GradCAM\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mexplanation_map_GradCAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexplanation_map_GradCAM\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mexplanation_map_GradCAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10e-30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xq/dngxcprn24qdwh7f57xlry5r0000gn/T/ipykernel_28507/393314700.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[0;34m(input_model, image, layer_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your code start from here for step 9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nealcaffrey/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"student\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 28, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "explanation_map_GradCAM = grad_cam(student_modelKD, np.expand_dims(image[2], axis=3), 'flatten_1')\n",
    "explanation_map_GradCAM -= explanation_map_GradCAM.min()\n",
    "explanation_map_GradCAM /= explanation_map_GradCAM.max()+10e-30\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "# plt.imshow(image[2])\n",
    "plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM only) - alpha=0.5')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(image[2])\n",
    "# plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.8)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM) - alpha=0.8')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(image[2])\n",
    "plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM) - alpha=0.8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjwJ5oziRvRn"
   },
   "source": [
    "# Implementing the state-of-the-art KD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q10lybAFRvZt"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Task 1-Question 3, distillation loss and student loss: https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk\n",
    "\n",
    "[2] Task 1-Question 4, gradient: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer\n",
    "\n",
    "[3] Task 1-Question 8, get flops: https://pypi.org/project/keras-flops/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25012ac4cf7441f693687fa97e861e7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38022535a8ae4875ad8cb2ae43189284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fc0ac74e6574800a761e017f6a096a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "403be929e9024411a153c32a8d9e7faa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40bc4ccbe60443ce98c9d1abd0dcfea7",
       "IPY_MODEL_a943481bd0e543e98336d234af4dd764",
       "IPY_MODEL_7ebc9447af7a4dd4aaadb32491bb47eb"
      ],
      "layout": "IPY_MODEL_3fc0ac74e6574800a761e017f6a096a6"
     }
    },
    "40bc4ccbe60443ce98c9d1abd0dcfea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90b50d41596f42e2b5d347f349746c67",
      "placeholder": "​",
      "style": "IPY_MODEL_b793841591f84ba2a70a8d592216e5bd",
      "value": "Dl Completed...: 100%"
     }
    },
    "7ebc9447af7a4dd4aaadb32491bb47eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade6bef4ba3b42f2af4cf92b536cae6b",
      "placeholder": "​",
      "style": "IPY_MODEL_38022535a8ae4875ad8cb2ae43189284",
      "value": " 4/4 [00:00&lt;00:00,  5.65 file/s]"
     }
    },
    "90b50d41596f42e2b5d347f349746c67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9855b4675bcc4a0b93606d95022ebca2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a943481bd0e543e98336d234af4dd764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9855b4675bcc4a0b93606d95022ebca2",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_25012ac4cf7441f693687fa97e861e7f",
      "value": 4
     }
    },
    "ade6bef4ba3b42f2af4cf92b536cae6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b793841591f84ba2a70a8d592216e5bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
